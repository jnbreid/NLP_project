{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "aa60b356",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import string\n",
    "\n",
    "def clean_text(text):\n",
    "    \"\"\"\n",
    "    Function to clean text data.\n",
    "    :param text: The input string containing the text to be cleaned.\n",
    "    :return: Cleaned text.\n",
    "    \"\"\"\n",
    "\n",
    "    # Convert text to lowercase\n",
    "    text = text.lower()\n",
    "\n",
    "    # Remove punctuation\n",
    "    text = text.translate(str.maketrans('', '', string.punctuation))\n",
    "\n",
    "    # Remove numbers\n",
    "    text = re.sub(r'\\d+', '', text)\n",
    "\n",
    "    # Remove extra whitespaces\n",
    "    text = text.strip()\n",
    "    text = re.sub(r'\\s+', ' ', text)\n",
    "\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "aaaa4b67",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     /home/user/welzs0/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     /home/user/welzs0/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     /home/user/welzs0/nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('punkt')\n",
    "nltk.download('wordnet')\n",
    "nltk.download('averaged_perceptron_tagger')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c430aa1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.corpus import wordnet\n",
    "\n",
    "def get_wordnet_pos(word):\n",
    "    \"\"\"\n",
    "    Map POS tag to the first character lemmatize() accepts.\n",
    "    \"\"\"\n",
    "    tag = nltk.pos_tag([word])[0][1][0].upper()\n",
    "    tag_dict = {\"J\": wordnet.ADJ,\n",
    "                \"N\": wordnet.NOUN,\n",
    "                \"V\": wordnet.VERB,\n",
    "                \"R\": wordnet.ADV}\n",
    "\n",
    "    return tag_dict.get(tag, wordnet.NOUN)\n",
    "\n",
    "def tokenize_and_lemmatize(text):\n",
    "    \"\"\"\n",
    "    Function to tokenize and lemmatize the input text.\n",
    "    :param text: The input string containing the text to be processed.\n",
    "    :return: A list of lemmatized tokens.\n",
    "    \"\"\"\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    tokenized_text = word_tokenize(text)\n",
    "    lemmatized_text = [lemmatizer.lemmatize(w, get_wordnet_pos(w)) for w in tokenized_text]\n",
    "    return lemmatized_text\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5e95c808",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_text(text):\n",
    "    cleaned_text = clean_text(text)\n",
    "    preprocessed_text = tokenize_and_lemmatize(cleaned_text)\n",
    "    \n",
    "    return preprocessed_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "67f3c123",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_dataset(dataset):\n",
    "    for element in tqdm(dataset, desc=\"Processing Text\"):\n",
    "        element['sentence'] = clean_text(element['sentence'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b23e75b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_dataset(dataset):\n",
    "    for element in tqdm(dataset, desc=\"Processing Text\"):\n",
    "        element['sentence'] = preprocess_text(element['sentence'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e23974b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Text: 100%|█████████████████████████████████████████████████████████████| 3602/3602 [00:05<00:00, 654.21it/s]\n",
      "Processing Text: 100%|█████████████████████████████████████████████████████████████| 2313/2313 [00:03<00:00, 753.14it/s]\n",
      "Processing Text: 100%|█████████████████████████████████████████████████████████████| 1120/1120 [00:01<00:00, 861.90it/s]\n",
      "Processing Text: 100%|███████████████████████████████████████████████████████████████| 638/638 [00:00<00:00, 891.32it/s]\n"
     ]
    }
   ],
   "source": [
    "preprocess_dataset(rest_train)\n",
    "preprocess_dataset(laptop_train)\n",
    "preprocess_dataset(rest_test)\n",
    "preprocess_dataset(laptop_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "56fd786a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'polarity': 'positive', 'term': 'server', 'id': '1592_0', 'sentence': ['our', 'server', 'be', 'very', 'helpful', 'and', 'friendly']}\n"
     ]
    }
   ],
   "source": [
    "print(rest_train[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32d9eafe",
   "metadata": {},
   "source": [
    "### TFIDF with Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "8f86f82b",
   "metadata": {},
   "outputs": [],
   "source": [
    "rest_train_sentences = [\" \".join(item['sentence']) for item in rest_train]\n",
    "rest_train_polarities = [item['polarity'] for item in rest_train]\n",
    "\n",
    "rest_test_sentences = [\" \".join(item['sentence']) for item in rest_test]\n",
    "rest_test_polarities = [item['polarity'] for item in rest_test]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "668e8901",
   "metadata": {},
   "outputs": [],
   "source": [
    "laptop_train_sentences = [\" \".join(item['sentence']) for item in laptop_train]\n",
    "laptop_train_polarities = [item['polarity'] for item in laptop_train]\n",
    "\n",
    "laptop_test_sentences = [\" \".join(item['sentence']) for item in laptop_test]\n",
    "laptop_test_polarities = [item['polarity'] for item in laptop_test]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d89e3916",
   "metadata": {},
   "source": [
    "### Roberta Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "033a3989",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_dataset(split={\"train\", \"test\", \"dev\"}, domain={\"rest\", \"laptop\"}):\n",
    "    with open(f'asc/{domain}/{split}.json', 'r') as file:\n",
    "        dataset = json.load(file)\n",
    "    return list(dataset.values())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "aab0e4e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "rest_train = load_dataset(split=\"train\", domain=\"rest\") + load_dataset(split=\"dev\", domain = \"rest\")\n",
    "rest_test = load_dataset(split=\"test\", domain=\"rest\")\n",
    "laptop_train = load_dataset(split=\"train\", domain=\"laptop\") + load_dataset(split=\"dev\", domain = \"laptop\")\n",
    "laptop_test = load_dataset(split=\"test\", domain=\"laptop\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "8009718e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Text: 100%|██████████████████████████████████████████████████████████| 3602/3602 [00:00<00:00, 119239.50it/s]\n",
      "Processing Text: 100%|██████████████████████████████████████████████████████████| 1120/1120 [00:00<00:00, 126849.58it/s]\n",
      "Processing Text: 100%|██████████████████████████████████████████████████████████| 2313/2313 [00:00<00:00, 108990.08it/s]\n",
      "Processing Text: 100%|████████████████████████████████████████████████████████████| 638/638 [00:00<00:00, 127239.12it/s]\n"
     ]
    }
   ],
   "source": [
    "clean_dataset(rest_train)\n",
    "clean_dataset(rest_test)\n",
    "clean_dataset(laptop_train)\n",
    "clean_dataset(laptop_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "f2e5dfec",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "9bf604f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "589ee4ac-1a9e-43cc-9ea5-27cd5112c07b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'polarity': 'positive',\n",
       " 'term': 'server',\n",
       " 'id': '1592_0',\n",
       " 'sentence': 'our server was very helpful and friendly'}"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rest_train[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "c0e8119d-6acd-4ea9-ba1a-a2bc93996c1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "rest_train_sentences = [item['term'] + ' [SEP] ' + item['sentence'] for item in rest_train]\n",
    "\n",
    "rest_test_sentences = [item['term'] + ' [SEP] ' + item['sentence'] for item in rest_test]\n",
    " \n",
    "laptop_train_sentences = [item['term'] + ' [SEP] ' + item['sentence'] for item in laptop_train]\n",
    "\n",
    "laptop_test_sentences = [item['term'] + ' [SEP] ' + item['sentence'] for item in laptop_test]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "782b1fa5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#rest_train_sentences = [\" \".join(item['sentence']) for item in rest_train]\n",
    "rest_train_polarities = [item['polarity'] for item in rest_train]\n",
    "\n",
    "#rest_test_sentences = [\" \".join(item['sentence']) for item in rest_test]\n",
    "rest_test_polarities = [item['polarity'] for item in rest_test]\n",
    "\n",
    "\n",
    "#laptop_train_sentences = [\" \".join(item['sentence']) for item in laptop_train]\n",
    "laptop_train_polarities = [item['polarity'] for item in laptop_train]\n",
    "\n",
    "#laptop_test_sentences = [\" \".join(item['sentence']) for item in laptop_test]\n",
    "laptop_test_polarities = [item['polarity'] for item in laptop_test]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce14fc44",
   "metadata": {},
   "source": [
    "To get results with the different subsets (e.g. laptop of restaurant dataset) simply remove the unwanted subset from the cell below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "26980b8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_sentences = rest_train_sentences + laptop_train_sentences\n",
    "train_polarities = rest_train_polarities + laptop_train_polarities\n",
    "\n",
    "test_sentences = rest_test_sentences + laptop_test_sentences\n",
    "test_polarities = rest_test_polarities + laptop_test_polarities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "0dd9534a-e5cf-42ef-85bc-eaccb5a59e66",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DC jack [SEP] then ive fixed the dc jack inside the unit rewired the dc jack to the outside of the laptop replaced the power brick\n",
      "neutral\n"
     ]
    }
   ],
   "source": [
    "random_index = random.randint(0, len(train_sentences))\n",
    "random_sentence = train_sentences[random_index]\n",
    "random_polarity = train_polarities[random_index]\n",
    "print(random_sentence)\n",
    "print(random_polarity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "eaa70845",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Positive : 3151\n",
      "Negative : 1671\n",
      "Neutral : 1093\n"
     ]
    }
   ],
   "source": [
    "pos = 0\n",
    "neg = 0\n",
    "neu = 0\n",
    "for polarity in train_polarities:\n",
    "    if polarity == 'positive':\n",
    "        pos += 1\n",
    "    elif polarity == 'negative':\n",
    "        neg += 1\n",
    "    elif polarity == 'neutral':\n",
    "        neu += 1\n",
    "print(f\"Positive : {pos}\")\n",
    "print(f\"Negative : {neg}\")\n",
    "print(f\"Neutral : {neu}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "335170ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['negative' 'neutral' 'positive']\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "label_encoder = LabelEncoder()\n",
    "y_train = label_encoder.fit_transform(train_polarities)\n",
    "y_test = label_encoder.transform(test_polarities)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "95ddd6f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import RobertaTokenizer, RobertaForSequenceClassification\n",
    "import torch\n",
    "from torch.utils.data import DataLoader, RandomSampler, SequentialSampler, TensorDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "b436246b-e9b4-40ca-a4d3-701257df5628",
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.over_sampling import SMOTE\n",
    "smote = SMOTE(random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "193a6d26",
   "metadata": {},
   "source": [
    "#### Kinds of Roberta Model we can try:\n",
    "- RoBERTa Base Model\n",
    "- RoBERTa Large Model\n",
    "- distilroberta-base\n",
    "- Visit Hugging Face for more...."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "580ae338",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import BertTokenizer\n",
    "model_name = 'roberta-base'\n",
    "# Load the BERT tokenizer\n",
    "tokenizer = RobertaTokenizer.from_pretrained(model_name)\n",
    "\n",
    "def encode_sentences(sentences, max_length=512):\n",
    "    input_ids = []\n",
    "    attention_masks = []\n",
    "\n",
    "    for sentence in sentences:\n",
    "        encoded_dict = tokenizer.encode_plus(\n",
    "                            sentence,                      # Sentence to encode\n",
    "                            add_special_tokens=True,       # Add '[CLS]' and '[SEP]'\n",
    "                            max_length=max_length,         # Pad & truncate all sentences\n",
    "                            padding='max_length',          # Pad all sentences to max length\n",
    "                            truncation=True,               # Explicitly truncate to max length\n",
    "                            return_attention_mask=True,    # Construct attention masks\n",
    "                            return_tensors='pt',           # Return pytorch tensors\n",
    "                        )\n",
    "        \n",
    "        input_ids.append(encoded_dict['input_ids'])\n",
    "        attention_masks.append(encoded_dict['attention_mask'])\n",
    "    return torch.cat(input_ids, dim=0), torch.cat(attention_masks, dim=0)\n",
    "\n",
    "# Encode the sentences (X_train and X_test)\n",
    "train_inputs, train_masks = encode_sentences(train_sentences)\n",
    "test_inputs, test_masks = encode_sentences(test_sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "ceb45a64",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_labels = torch.tensor(y_train)\n",
    "test_labels = torch.tensor(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "e06db979",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler\n",
    "\n",
    "batch_size = 16  # Adjust this according to your GPU capacity\n",
    "\n",
    "# Create the DataLoader for our training set\n",
    "train_data = TensorDataset(train_inputs, train_masks, train_labels)\n",
    "train_sampler = RandomSampler(train_data)\n",
    "train_dataloader = DataLoader(train_data, sampler=train_sampler, batch_size=batch_size)\n",
    "\n",
    "# Create the DataLoader for our test set\n",
    "test_data = TensorDataset(test_inputs, test_masks, test_labels)\n",
    "test_sampler = SequentialSampler(test_data)\n",
    "test_dataloader = DataLoader(test_data, sampler=test_sampler, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "0acc36b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at roberta-base and are newly initialized: ['classifier.out_proj.weight', 'classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RobertaForSequenceClassification(\n",
       "  (roberta): RobertaModel(\n",
       "    (embeddings): RobertaEmbeddings(\n",
       "      (word_embeddings): Embedding(50265, 768, padding_idx=1)\n",
       "      (position_embeddings): Embedding(514, 768, padding_idx=1)\n",
       "      (token_type_embeddings): Embedding(1, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (encoder): RobertaEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0): RobertaLayer(\n",
       "          (attention): RobertaAttention(\n",
       "            (self): RobertaSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): RobertaSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): RobertaIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): RobertaOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (1): RobertaLayer(\n",
       "          (attention): RobertaAttention(\n",
       "            (self): RobertaSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): RobertaSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): RobertaIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): RobertaOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (2): RobertaLayer(\n",
       "          (attention): RobertaAttention(\n",
       "            (self): RobertaSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): RobertaSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): RobertaIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): RobertaOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (3): RobertaLayer(\n",
       "          (attention): RobertaAttention(\n",
       "            (self): RobertaSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): RobertaSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): RobertaIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): RobertaOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (4): RobertaLayer(\n",
       "          (attention): RobertaAttention(\n",
       "            (self): RobertaSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): RobertaSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): RobertaIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): RobertaOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (5): RobertaLayer(\n",
       "          (attention): RobertaAttention(\n",
       "            (self): RobertaSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): RobertaSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): RobertaIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): RobertaOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (6): RobertaLayer(\n",
       "          (attention): RobertaAttention(\n",
       "            (self): RobertaSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): RobertaSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): RobertaIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): RobertaOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (7): RobertaLayer(\n",
       "          (attention): RobertaAttention(\n",
       "            (self): RobertaSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): RobertaSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): RobertaIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): RobertaOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (8): RobertaLayer(\n",
       "          (attention): RobertaAttention(\n",
       "            (self): RobertaSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): RobertaSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): RobertaIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): RobertaOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (9): RobertaLayer(\n",
       "          (attention): RobertaAttention(\n",
       "            (self): RobertaSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): RobertaSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): RobertaIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): RobertaOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (10): RobertaLayer(\n",
       "          (attention): RobertaAttention(\n",
       "            (self): RobertaSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): RobertaSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): RobertaIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): RobertaOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (11): RobertaLayer(\n",
       "          (attention): RobertaAttention(\n",
       "            (self): RobertaSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): RobertaSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): RobertaIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): RobertaOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (classifier): RobertaClassificationHead(\n",
       "    (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "    (dropout): Dropout(p=0.1, inplace=False)\n",
       "    (out_proj): Linear(in_features=768, out_features=3, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = RobertaForSequenceClassification.from_pretrained(\n",
    "    model_name,  # Use the 12-layer BERT model, with an uncased vocab\n",
    "    num_labels=3,        # Number of output labels (3 for positive/negative/neutral)\n",
    "    output_attentions=False,\n",
    "    output_hidden_states=False,\n",
    ")\n",
    "\n",
    "# Tell the model to run on GPU\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "da3cb544",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import get_linear_schedule_with_warmup\n",
    "import torch\n",
    "# Implement the training loop\n",
    "epochs = 5\n",
    "# Define the optimizer\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=2e-5, eps=1e-8)\n",
    "\n",
    "# Total number of training steps\n",
    "total_steps = len(train_dataloader) * epochs\n",
    "\n",
    "# Create the learning rate scheduler.\n",
    "scheduler = get_linear_schedule_with_warmup(optimizer, num_warmup_steps=0, num_training_steps=total_steps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "5d58f0d0-ecc1-4843-a4b2-3b5eccc66273",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import precision_recall_fscore_support, accuracy_score, confusion_matrix\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "17b75fee",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                        \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Average training loss: 0.26\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████| 110/110 [00:12<00:00,  8.51it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8498\n",
      "Precision: 0.8522\n",
      "Recall: 0.8498\n",
      "F1-Score: 0.8491\n",
      "  Accuracy increased from 0.85 to 0.00, saving model.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                        \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Average training loss: 0.17\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████| 110/110 [00:12<00:00,  8.50it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8510\n",
      "Precision: 0.8482\n",
      "Recall: 0.8510\n",
      "F1-Score: 0.8430\n",
      "  Accuracy increased from 0.85 to 0.85, saving model.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                        \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Average training loss: 0.10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████| 110/110 [00:12<00:00,  8.48it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8589\n",
      "Precision: 0.8553\n",
      "Recall: 0.8589\n",
      "F1-Score: 0.8554\n",
      "  Accuracy increased from 0.86 to 0.85, saving model.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                        \r"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[46], line 18\u001b[0m\n\u001b[1;32m     16\u001b[0m outputs \u001b[38;5;241m=\u001b[39m model(b_input_ids, token_type_ids\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, attention_mask\u001b[38;5;241m=\u001b[39mb_input_mask, labels\u001b[38;5;241m=\u001b[39mb_labels)\n\u001b[1;32m     17\u001b[0m loss \u001b[38;5;241m=\u001b[39m outputs\u001b[38;5;241m.\u001b[39mloss\n\u001b[0;32m---> 18\u001b[0m total_train_loss \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[43mloss\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mitem\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     20\u001b[0m \u001b[38;5;66;03m# Perform a backward pass\u001b[39;00m\n\u001b[1;32m     21\u001b[0m loss\u001b[38;5;241m.\u001b[39mbackward()\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "best_accuracy = 0\n",
    "for epoch in range(0, epochs):\n",
    "    # Training step\n",
    "    model.train()\n",
    "    total_train_loss = 0\n",
    "    progress_bar = tqdm(train_dataloader, desc=\"Epoch {:1d}\".format(epoch+1), leave=False, disable=False)\n",
    "    for batch in progress_bar:\n",
    "        b_input_ids = batch[0].to(device)\n",
    "        b_input_mask = batch[1].to(device)\n",
    "        b_labels = batch[2].to(device)\n",
    "\n",
    "        # Clear previously calculated gradients\n",
    "        model.zero_grad()        \n",
    "\n",
    "        # Perform a forward pass\n",
    "        outputs = model(b_input_ids, token_type_ids=None, attention_mask=b_input_mask, labels=b_labels)\n",
    "        loss = outputs.loss\n",
    "        total_train_loss += loss.item()\n",
    "\n",
    "        # Perform a backward pass\n",
    "        loss.backward()\n",
    "\n",
    "        # Update parameters and take a step using the computed gradient\n",
    "        optimizer.step()\n",
    "        scheduler.step()\n",
    "        # Update the progress bar\n",
    "        progress_bar.set_postfix({'training_loss': '{:.3f}'.format(loss.item()/len(batch))})\n",
    "    \n",
    "    # Calculate the average loss over the training data.\n",
    "    avg_train_loss = total_train_loss / len(train_dataloader)            \n",
    "    print(f\"  Average training loss: {avg_train_loss:.2f}\")\n",
    "    \n",
    "    model.eval()\n",
    "\n",
    "    # Initialize variables to gather predictions and true labels\n",
    "    all_predictions = []\n",
    "    all_true_labels = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        total_eval_loss = 0\n",
    "        for batch in tqdm(test_dataloader):\n",
    "            b_input_ids = batch[0].to(device)\n",
    "            b_input_mask = batch[1].to(device)\n",
    "            b_labels = batch[2].to(device)\n",
    "\n",
    "            outputs = model(b_input_ids, token_type_ids=None, attention_mask=b_input_mask, labels=b_labels)\n",
    "\n",
    "            loss = outputs.loss\n",
    "            total_eval_loss += loss.item()\n",
    "\n",
    "            logits = outputs.logits.detach().cpu().numpy()\n",
    "            label_ids = b_labels.to('cpu').numpy()\n",
    "\n",
    "            # Store predictions and true labels\n",
    "            all_predictions.extend(np.argmax(logits, axis=1).flatten())\n",
    "            all_true_labels.extend(label_ids.flatten())\n",
    "    precision, recall, f1_score, _ = precision_recall_fscore_support(all_true_labels, all_predictions, average='weighted')\n",
    "    accuracy = accuracy_score(all_true_labels, all_predictions)\n",
    "    print(f'Accuracy: {accuracy:.4f}')\n",
    "    print(f'Precision: {precision:.4f}')\n",
    "    print(f'Recall: {recall:.4f}')\n",
    "    print(f'F1-Score: {f1_score:.4f}')\n",
    "    if accuracy >= best_accuracy:\n",
    "        print(f\"  Accuracy increased from {accuracy:.2f} to {best_accuracy:.2f}, saving model.\")\n",
    "        best_accuracy = accuracy\n",
    "        best_model_state = model.state_dict()\n",
    "torch.save(best_model_state, 'best_BERT_model.bin')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "e0c54f53",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████| 110/110 [00:12<00:00,  8.79it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8544\n",
      "Precision: 0.8497\n",
      "Recall: 0.8544\n",
      "F1-Score: 0.8499\n",
      "Confusion Matrix:\n",
      " [[ 265   35   24]\n",
      " [  55  223   87]\n",
      " [  20   35 1014]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'cm' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[57], line 36\u001b[0m\n\u001b[1;32m     33\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mF1-Score: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mf1_score\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.4f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m     34\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mConfusion Matrix:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m'\u001b[39m, conf_matrix)\n\u001b[0;32m---> 36\u001b[0m TP \u001b[38;5;241m=\u001b[39m \u001b[43mcm\u001b[49m[\u001b[38;5;241m2\u001b[39m, \u001b[38;5;241m2\u001b[39m]\n\u001b[1;32m     37\u001b[0m FP \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39msum(cm[:, \u001b[38;5;241m2\u001b[39m]) \u001b[38;5;241m-\u001b[39m TP\n\u001b[1;32m     38\u001b[0m precision_positve \u001b[38;5;241m=\u001b[39m TP \u001b[38;5;241m/\u001b[39m (TP \u001b[38;5;241m+\u001b[39m FÜ)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'cm' is not defined"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import precision_score\n",
    "model.eval()\n",
    "\n",
    "# Initialize variables to gather predictions and true labels\n",
    "all_predictions = []\n",
    "all_true_labels = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    total_eval_loss = 0\n",
    "    for batch in tqdm(test_dataloader):\n",
    "        b_input_ids = batch[0].to(device)\n",
    "        b_input_mask = batch[1].to(device)\n",
    "        b_labels = batch[2].to(device)\n",
    "        \n",
    "        outputs = model(b_input_ids, token_type_ids=None, attention_mask=b_input_mask, labels=b_labels)\n",
    "    \n",
    "        loss = outputs.loss\n",
    "        total_eval_loss += loss.item()\n",
    "        \n",
    "        logits = outputs.logits.detach().cpu().numpy()\n",
    "        label_ids = b_labels.to('cpu').numpy()\n",
    "        \n",
    "        # Store predictions and true labels\n",
    "        all_predictions.extend(np.argmax(logits, axis=1).flatten())\n",
    "        all_true_labels.extend(label_ids.flatten())\n",
    "precision, recall, f1_score, _ = precision_recall_fscore_support(all_true_labels, all_predictions, average='weighted')\n",
    "#0 neg, 1 neut, 2 pos\n",
    "accuracy = accuracy_score(all_true_labels, all_predictions)\n",
    "conf_matrix = confusion_matrix(all_true_labels, all_predictions)\n",
    "print(f'Accuracy: {accuracy:.4f}')\n",
    "print(f'Precision: {precision:.4f}')\n",
    "print(f'Recall: {recall:.4f}')\n",
    "print(f'F1-Score: {f1_score:.4f}')\n",
    "print('Confusion Matrix:\\n', conf_matrix)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "98536ebb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision Positive 0.9013333333333333\n",
      "Precision Negative 0.7794117647058824\n",
      "Precision Neutral 0.7610921501706485\n"
     ]
    }
   ],
   "source": [
    "TP = conf_matrix[2, 2]\n",
    "FP = np.sum(conf_matrix[:, 2]) - TP\n",
    "precision_positve = TP / (TP + FP)\n",
    "\n",
    "\n",
    "TP = conf_matrix[0, 0]\n",
    "FP = np.sum(conf_matrix[:, 0]) - TP\n",
    "precision_negative = TP / (TP + FP)\n",
    "\n",
    "TP = conf_matrix[1, 1]\n",
    "FP = np.sum(conf_matrix[:, 1]) - TP\n",
    "precision_neutral = TP / (TP + FP)\n",
    "print(f\"Precision Positive {precision_positve}\")\n",
    "print(f\"Precision Negative {precision_negative}\")\n",
    "print(f\"Precision Neutral {precision_neutral}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
